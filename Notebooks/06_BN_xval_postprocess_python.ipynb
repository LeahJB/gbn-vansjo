{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bayes_net_utils as bn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we read in the cross validation results from the previous notebook and calculate a wider range of model performance statistics than are available within bnearn's cross validation function, in particular by discretizing the simulated output and calculating classification error, Matthew's correlation coefficient and the ROC_AUC score. This allows the continuous network to be compared to predictive performance of a discrete network.\n",
    "\n",
    "In addition, we re-calculate correlation coefficients and mse. These can be calculated within bnlearn's CV function, but it was easier to automate the calculation here for all the CV runs done. Results match those obtained within bnlearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "\n",
    "# Folder containing files of observed and predicted values from each cross validation run. Produced in notebook BN_development_1Season_R\n",
    "CV_obs_sim_folder = \"../Data/CrossValidation/LOOCV_predictions\"\n",
    "\n",
    "# Boundaries dictionary, copied from notebook B_seasonal_data_matrix_1Season\n",
    "bound_dict = {\n",
    "             'TP': [29.5], # No data below 20, so drop this class boundary. 29.5 is middle of 'Mod' class   \n",
    "             'chla': [20.0],  # WFD boundaries: [10.5, 20.0]. But only 6 d.p. under 10.5 so merge G and M classes and use 20.\n",
    "                              # For predicting cyano, would be better 17.4.   \n",
    "             'colour': [48.0], # 66th percentile\n",
    "             'cyano': [1.0], # M-P boundary is 2.0, but there were only 2 values in this class, rest above\n",
    "             }\n",
    "\n",
    "# Alter the boundaries in the boundaries dict for cyano, to take account of the box-cox transformation applied to the continuous\n",
    "# data:  y* = (y^L - 1)/L, where we used lambda = 0.1 when transforming original cyano data\n",
    "# bound_dict['cyano'] = [bound_dict['cyano'][0]**0.1 - 1]\n",
    "\n",
    "met_source = 'metno' #'metno' or 'era5'\n",
    "\n",
    "var_li = ['TP', 'chla', 'cyano', 'colour'] # What do you want to produce stats for? Need to have corresponding files in 'Data/CrossValidation/%s' %met_source folder\n",
    "\n",
    "# Pre-calculated standard deviations (from fitting of GBN in a later notebook)\n",
    "sd_fpath = \"../Data/FittedNetworkDiagnostics/GBN_%s_1981-2018_stdevs.csv\" %(met_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcox_backtransform(x, lambda_param, bias_adj=True, sd_cyano=None):\n",
    "    \"\"\"\n",
    "    x: value to back transform\n",
    "    lambda_param: lambda used in box cox transform\n",
    "    bias_adj: bias adjust the values when back-transforming? True or False\n",
    "    sigma: if bias adjusting, this is the standard deviation of the box-cox transformed observations\n",
    "\n",
    "    returns: back-transformed value\n",
    "    \"\"\"\n",
    "\n",
    "    if bias_adj is True:\n",
    "        backtransformed_value = ((x * lambda_param + 1) ** (1 / lambda_param)) * (\n",
    "            1 + (((sd_cyano**2) * (1 - lambda_param)) / (2 * (lambda_param * x + 1) ** 2))\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        backtransformed_value = (x * 0.1 + 1) ** (1 / 0.1)\n",
    "\n",
    "    return backtransformed_value\n",
    "\n",
    "\n",
    "def xval_postprocess(var, fpath, sd_cyano=None):\n",
    "    \"\"\"\n",
    "    Function to read in a csv of observed and predicted values from a continuous\n",
    "    Bayesian belief network produced in BNLearn R notebook, calculate correlation\n",
    "    coefficient and mean squared error, and then classify according to WFD and\n",
    "    work out classification error, Matthew's correlation coefficient and ROC_AUC.\n",
    "    If the cross validation input file is stochastic (i.e. contains multiple runs\n",
    "    for the same variable), model performance statistics are averaged.\n",
    "\n",
    "    Inputs:\n",
    "        var: string, one of 'TP','chla','cyano','colour'\n",
    "        fpath: string giving location of csv to be read in. csv should have columns:\n",
    "                'obs_1','pred_1','obs_2','pred_2',... where _1, _2, etc. is the cross\n",
    "                validation run number.\n",
    "        sd_cyano: standard deviation of the box-cox transformed cyanobacteria observations,\n",
    "                  for use when doing bias-adjusted back transformation\n",
    "\n",
    "    Returns a series of model performance statistics for the variable.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # Read in data\n",
    "    df = pd.read_csv(fpath, index_col=0)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # Split into separate dataframes for each cross validation run\n",
    "    cont_dict = {}  # Key: run number, returns df with obs and pred\n",
    "    for i, col_name in enumerate(df.columns):\n",
    "        if i % 2 == 0:  # If even, i.e. only do this for half the cols\n",
    "            run_no = int(col_name.split(\"_\", 1)[1])\n",
    "            if run_no == 1:\n",
    "                temp_df = df.iloc[:, [0, 1]]\n",
    "            else:\n",
    "                temp_df = df.iloc[:, [2 * run_no - 2, 2 * run_no - 1]]\n",
    "\n",
    "            temp_df.columns = [\"obs\", \"pred\"]\n",
    "\n",
    "            # If variable is cyanobacteria, transform observed and predicted to original data scale\n",
    "            if var == \"cyano\":\n",
    "\n",
    "                transformed_df = pd.DataFrame()\n",
    "                transformed_df[\"obs\"] = temp_df[\"obs\"].apply(\n",
    "                    boxcox_backtransform,\n",
    "                    lambda_param=0.1,\n",
    "                    bias_adj=False\n",
    "                )\n",
    "\n",
    "                # With bias-adjusted back transformation, to estimate the mean\n",
    "                transformed_df[\"pred\"] = temp_df[\"pred\"].apply(\n",
    "                    boxcox_backtransform,\n",
    "                    lambda_param=0.1,\n",
    "                    bias_adj=True,\n",
    "                    sd_cyano=sd_cyano\n",
    "                )\n",
    "\n",
    "                cont_dict[run_no] = transformed_df\n",
    "\n",
    "            else:\n",
    "                # Add to dict\n",
    "                cont_dict[run_no] = temp_df\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # Calculate statistics (both continuous and discrete)\n",
    "\n",
    "    cc_dict = {}  # key: run_no, returns correlation coeff\n",
    "    rmse_dict = {}  # key: run_no, returns mse (pred - obs)\n",
    "    classified_dict = (\n",
    "        {}\n",
    "    )  # Key: run number. Returns df with cols 'obs' and 'pred', discrete data\n",
    "    class_error_dict = {}\n",
    "    mcc_dict = {}\n",
    "    roc_auc_dict = {}\n",
    "\n",
    "    for run_no in cont_dict.keys():\n",
    "\n",
    "        cont_df = cont_dict[run_no]  # df with continuous data\n",
    "\n",
    "        # Correlation coefficients\n",
    "        cc_dict[run_no] = cont_df[\"obs\"].corr(cont_df[\"pred\"], method=\"pearson\")\n",
    "\n",
    "        # Root mean square error\n",
    "        rmse = np.sqrt(np.mean(((cont_df[\"pred\"] - cont_df[\"obs\"]) ** 2)))\n",
    "        rmse_dict[run_no] = rmse\n",
    "\n",
    "        # Classify obs and pred into WFD (or related) class boundaries\n",
    "        disc_df = pd.DataFrame(\n",
    "            index=cont_df.index, columns=cont_df.columns\n",
    "        )  # New empty df to be populated\n",
    "        for col in cont_df.columns:\n",
    "            disc_df[col] = cont_df[col].apply(\n",
    "                lambda x: bn.discretize(bound_dict[var], x)\n",
    "            )\n",
    "        classified_dict[run_no] = disc_df\n",
    "\n",
    "        # Calculate classification error (proportion of time model predicted class correctly)\n",
    "        error = bn.classification_error(disc_df[\"obs\"], disc_df[\"pred\"])\n",
    "        class_error_dict[run_no] = error\n",
    "\n",
    "        # Calculate matthew's correlation coefficient and ROC_AUC score\n",
    "        mcc_dict[run_no] = matthews_corrcoef(\n",
    "            disc_df[\"obs\"].values, disc_df[\"pred\"].values\n",
    "        )\n",
    "        roc_auc_dict[run_no] = roc_auc_score(\n",
    "            disc_df[\"obs\"].values, disc_df[\"pred\"].values\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # Aggregate results over repeat CV runs\n",
    "\n",
    "    corr_coeffs = pd.Series(cc_dict)  # These match those calculated within bnlearn's CV function\n",
    "    rmses = pd.Series(rmse_dict)\n",
    "    errors = pd.Series(class_error_dict)\n",
    "    mccs = pd.Series(mcc_dict)\n",
    "    roc_aucs = pd.Series(roc_auc_dict)\n",
    "\n",
    "    # Combine all stats into one series\n",
    "    results_series = pd.Series(\n",
    "        data=np.array(\n",
    "            [\n",
    "                corr_coeffs.mean(),\n",
    "                rmses.mean(),\n",
    "                errors.mean(),\n",
    "                mccs.mean(),\n",
    "                roc_aucs.mean(),\n",
    "            ]\n",
    "        ),\n",
    "        index=[\"mean_CC\", \"mean_rmse\", \"mean_class_error\", \"mean_mcc\", \"mean_ROC_AUC\"],\n",
    "    )\n",
    "\n",
    "    return results_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chla': ['chla_cont_LOOCV_fromPredictableNodes_metno.csv',\n",
       "  'chla_cont_LOOCV_fromPredictableNodes_nomet.csv'],\n",
       " 'cyano': ['cyano_cont_LOOCV_fromPredictableNodes_nomet.csv',\n",
       "  'cyano_cont_LOOCV_fromPredictableNodes_metno.csv'],\n",
       " 'colour': ['colour_cont_LOOCV_fromPredictableNodes_nomet.csv',\n",
       "  'colour_cont_LOOCV_fromPredictableNodes_metno.csv'],\n",
       " 'TP': ['TP_cont_LOOCV_fromPredictableNodes_nomet.csv',\n",
       "  'TP_cont_LOOCV_fromPredictableNodes_metno.csv']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup: loop through CV results files and add to a dict\n",
    "fpaths = os.listdir(CV_obs_sim_folder)\n",
    "\n",
    "fpath_dict = {}\n",
    "for file in fpaths:\n",
    "    var = file.split('_')[0]\n",
    "    if var in var_li:\n",
    "        if var in fpath_dict.keys():\n",
    "            fpath_dict[var].append(file)\n",
    "        else:\n",
    "            fpath_dict[var] = [file]\n",
    "\n",
    "fpath_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>met_data</th>\n",
       "      <th>mean_CC</th>\n",
       "      <th>mean_rmse</th>\n",
       "      <th>mean_class_error</th>\n",
       "      <th>mean_mcc</th>\n",
       "      <th>mean_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>metno</td>\n",
       "      <td>0.574923</td>\n",
       "      <td>3.958973</td>\n",
       "      <td>0.330263</td>\n",
       "      <td>0.335971</td>\n",
       "      <td>0.666250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "      <td>nomet</td>\n",
       "      <td>0.574923</td>\n",
       "      <td>3.958973</td>\n",
       "      <td>0.330263</td>\n",
       "      <td>0.335971</td>\n",
       "      <td>0.666250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chla</td>\n",
       "      <td>metno</td>\n",
       "      <td>0.546171</td>\n",
       "      <td>4.764127</td>\n",
       "      <td>0.338158</td>\n",
       "      <td>0.049825</td>\n",
       "      <td>0.519613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chla</td>\n",
       "      <td>nomet</td>\n",
       "      <td>0.541435</td>\n",
       "      <td>4.758443</td>\n",
       "      <td>0.318421</td>\n",
       "      <td>0.082392</td>\n",
       "      <td>0.530808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colour</td>\n",
       "      <td>metno</td>\n",
       "      <td>0.846322</td>\n",
       "      <td>8.780196</td>\n",
       "      <td>0.244737</td>\n",
       "      <td>0.436296</td>\n",
       "      <td>0.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colour</td>\n",
       "      <td>nomet</td>\n",
       "      <td>0.823366</td>\n",
       "      <td>9.352747</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.464775</td>\n",
       "      <td>0.727692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cyano</td>\n",
       "      <td>metno</td>\n",
       "      <td>0.374754</td>\n",
       "      <td>1.905897</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.491434</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyano</td>\n",
       "      <td>nomet</td>\n",
       "      <td>0.473509</td>\n",
       "      <td>1.755389</td>\n",
       "      <td>0.310870</td>\n",
       "      <td>0.494643</td>\n",
       "      <td>0.702083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable met_data   mean_CC  mean_rmse  mean_class_error  mean_mcc  \\\n",
       "0       TP    metno  0.574923   3.958973          0.330263  0.335971   \n",
       "1       TP    nomet  0.574923   3.958973          0.330263  0.335971   \n",
       "2     chla    metno  0.546171   4.764127          0.338158  0.049825   \n",
       "3     chla    nomet  0.541435   4.758443          0.318421  0.082392   \n",
       "4   colour    metno  0.846322   8.780196          0.244737  0.436296   \n",
       "5   colour    nomet  0.823366   9.352747          0.236842  0.464775   \n",
       "6    cyano    metno  0.374754   1.905897          0.313043  0.491434   \n",
       "7    cyano    nomet  0.473509   1.755389          0.310870  0.494643   \n",
       "\n",
       "   mean_ROC_AUC  \n",
       "0      0.666250  \n",
       "1      0.666250  \n",
       "2      0.519613  \n",
       "3      0.530808  \n",
       "4      0.706000  \n",
       "5      0.727692  \n",
       "6      0.700000  \n",
       "7      0.702083  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the standard deviation of the box cox transformed observations, for use in\n",
    "# back-transforming the cyanobacteria predictions\n",
    "sd_cyano = 1.29  # period 1981-2018, box cox transformed with lambda = 0.1\n",
    "\n",
    "# Start looping through the CV results files and carry out post-processing\n",
    "series_li = []\n",
    "for var in var_li:\n",
    "    for file in fpath_dict[var]:\n",
    "        in_fpath = os.path.join(CV_obs_sim_folder, file)\n",
    "\n",
    "        # Calculate stats\n",
    "        stats_series = xval_postprocess(var, in_fpath, sd_cyano=sd_cyano)\n",
    "\n",
    "        # Tidy\n",
    "        stats_series.name = file.split('.')[0]\n",
    "        series_li.append(stats_series)\n",
    "\n",
    "# Combine stats for all variables into one dataframe and tidy\n",
    "df = pd.concat(series_li, axis=1, keys=[s.name for s in series_li]).transpose()\n",
    "df['Variable'] = [i.split('_')[0] for i in list(df.index)]\n",
    "df['met_data'] = [i.split('_')[-1] for i in list(df.index)]\n",
    "df = df.set_index(['Variable', 'met_data']).sort_index()\n",
    "\n",
    "# df['nodes_used'] = [i.split('_')[2][4:-5] for i in list(df.index)] # Comment out if just using predictable nodes\n",
    "# df['wind_yn'] = [i.split('_')[-2] for i in list(df.index)]\n",
    "# df.loc[df['wind_yn']!='noWind','wind_yn'] = 'Wind'\n",
    "# df = df.set_index(['Variable','met_data','nodes_used','wind_yn']).sort_index()\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "# Write to csv\n",
    "df.to_csv('../Data/CrossValidation/Stats/LOOCV_results_bias-adj-cyano.csv', index=False)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
